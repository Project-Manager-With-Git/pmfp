import numpy as np
import torch
from torch.autograd import Variable as Var
import torch.nn.functional as Func
import torch.nn as nn
from torchvision import datasets, transforms
from PIL import Image
from .net import Net


class Model:
    """
    """
    TRAIN_LOG_TEMPLATE = "TRAIN Epoch: {epoch} [{past_epoch}/{total_epoch} ({rate:.0f}%)]\tLoss: {loss:.6f}"
    TEST_LOG_TEMPLATE = '\nTest set: Average loss: {loss:.4f}, Accuracy: {correct}/{total_test} ({rate:.0f}%)\n'

    @classmethod
    def load_pkl(cls, model_path="./model.pkl", **kwargs):
        model = cls(**kwargs)
        model._model.load_state_dict(torch.load(model_path))
        return model

    def __init__(self,
                 net: torch.nn.Module=Net,
                 *,
                 epochs: int = 10,
                 batch_size: int = 64,
                 test_batch_size: int=1000,
                 dataset_path: str = "../data",
                 cuda: bool =False,
                 lr: float=0.01,
                 momentum: float=0.5,
                 log_interval: int=10,
                 seed: int=1,
                 log_detail: bool=False,
                 model_path: str="./model.pkl",
                 **kwargs
                 )->None:
        """
        """
        self.model_path = model_path
        self.log_detail = log_detail
        self.epochs = epochs
        self._model = net(**kwargs)
        self.use_cuda = cuda and torch.cuda.is_available()
        self.log_interval = log_interval
        torch.manual_seed(seed)
        loader_kwargs = {}
        if self.use_cuda:
            torch.cuda.manual_seed(seed)
            loader_kwargs.update({'num_workers': 1, 'pin_memory': True})
            self._model.cuda()
        self._optimizer = torch.optim.SGD(self._model.parameters(), lr=lr, momentum=momentum)
        self._train_loader = torch.utils.data.DataLoader(
            datasets.MNIST(
                dataset_path,
                train=True,
                download=True,
                transform=transforms.Compose(
                    [
                        transforms.RandomHorizontalFlip(),
                        # transforms.RandomResizedCrop(20),
                        transforms.ToTensor(),
                        transforms.Normalize((0.1307,), (0.3081,))
                    ]
                )
            ),
            batch_size=batch_size, shuffle=True, **loader_kwargs
        )
        self._test_loader = torch.utils.data.DataLoader(
            datasets.MNIST(
                dataset_path,
                train=False,
                transform=transforms.Compose(
                    [
                        # transforms.CenterCrop(20),
                        transforms.ToTensor(),
                        transforms.Normalize((0.1307,), (0.3081,))
                    ]
                )
            ),
            batch_size=test_batch_size,
            shuffle=True,
            **loader_kwargs
        )

    def train_epoch(self, epoch):
        """用于训练模型一个epoch."""
        print("TRAIN Epoch: {} starting".format(epoch))
        self._model.train()
        for batch_idx, (data, target) in enumerate(self._train_loader):
            if self.use_cuda:
                data, target = data.cuda(), target.cuda()
            data, target = Var(data), Var(target)
            self._optimizer.zero_grad()
            output = self._model(data)
            loss = Func.nll_loss(output, target)
            loss.backward()
            self._optimizer.step()
            if batch_idx % self.log_interval == 0 and self.log_detail is True:
                print(
                    self.TRAIN_LOG_TEMPLATE.format(
                        epoch=epoch,
                        past_epoch=batch_idx * len(data),
                        total_epoch=len(self._train_loader.dataset),
                        rate=100. * batch_idx / len(self._train_loader),
                        loss=loss.data[0]
                    )
                )
        print("TRAIN Epoch: {} end with loss {:.6f}".format(epoch, loss.data[0]))

    def test(self):
        """测试."""
        self._model.eval()
        test_loss = 0
        correct = 0
        show = True
        for data, target in self._test_loader:
            if show is True:
                print(data[0])
                print(target[0])
                show = False
            if self.use_cuda:
                data, target = data.cuda(), target.cuda()
            data, target = Var(data, volatile=True), Var(target)
            output = self._model(data)
            test_loss += Func.nll_loss(output, target, size_average=False).data[0]  # sum up batch loss
            pred = output.data.max(1, keepdim=True)[1]  # get the index of the max log-probability
            correct += pred.eq(target.data.view_as(pred)).cpu().sum()

        test_loss /= len(self._test_loader.dataset)
        print(
            self.TEST_LOG_TEMPLATE.format(
                loss=test_loss,
                correct=correct,
                total_test=len(self._test_loader.dataset),
                rate=100. * correct / len(self._test_loader.dataset)
            )
        )

    def train(self):
        print("Train start")
        for epoch in range(1, self.epochs + 1):
            self.train_epoch(epoch)
            self.test()
        print("save model to ")
        torch.save(self._model.state_dict(), self.model_path)
        input_names = ["learned_1"]
        output_names = ["output1"]
        torch.onnx.export(
            self._model,
            dummy_input,
            "model.proto",
            verbose=True,
            input_names=input_names,
            output_names=output_names
        )
        print("Train end")

    @staticmethod
    def img_transform(infile):
        im = Image.open(infile)
        w, h = im.size
        if not (w == 28 and h == 28):
            half_size = min(w, h) * 0.12
            half_the_width = w / 2
            half_the_height = h / 2
            im = im.crop(
                (
                    half_the_width - half_size,
                    half_the_height - half_size,
                    half_the_width + half_size,
                    half_the_height + half_size
                )
            )
            im = im.resize((28, 28))
        im.save("mini.jpg")
        im = im.convert('L')
        arr = []
        for i in range(28):
            for j in range(28):
                # mnist 里的颜色是0代表白色（背景），1.0代表黑色
                print(im.getpixel((i, j)))
                #pixel = 1.0 - float(im.getpixel((i, j)))  / 255.0
                pixel = 255 - im.getpixel((j, i))
                # pixel = 255.0 - float(img.getpixel((j, i))) # 如果是0-255的颜色值
                arr.append(pixel)

        arr1 = np.array(arr).reshape([28, 28])
        im = Image.fromarray(arr1, mode='L')
        return im

    def predict(self, infile):
        im = self.__class__.img_transform(infile)
        img_tensor = transforms.ToTensor()(im)
        img_tensor = transforms.Normalize((0.1307,), (0.3081,))(img_tensor)
        img_tensor = img_tensor.unsqueeze(0)
        print(img_tensor)
        input = torch.autograd.Variable(img_tensor, volatile=True)
        target = torch.autograd.Variable(
            torch.LongTensor(list(range(10))),
            volatile=True
        )
        result = self._model(input)
        topv, topi = result.data.topk(3, 1, True)
        print(topv)
        print(topi)
        # result = result.data.numpy()[0]
        # print(result)
        # maxval = max(list(enumerate(result)), key=lambda x: x[1])
        # print(maxval)
        #return maxval[0]
